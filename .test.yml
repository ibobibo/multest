stages:
  - prepare
  - test

services:
  - docker:dind

variables:
  BASE_IMAGE_NAME: wdio-test-runner

# Create a docker image that contains this codebase and a node.js runtime. This image
# will run the headless tests.
"Build WDIO Test Image":
  stage: prepare
  image: docker:stable
  variables:
    TEST_IMAGE_NAME: ${SPRYLAB_REGISTRY}/${BASE_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
    # This image is just used to speed up all build pipeline steps assuming npm dependencies
    # do not change too often across branches
    TEST_CACHE_IMAGE_NAME: ${SPRYLAB_REGISTRY}/${BASE_IMAGE_NAME}
  before_script:
    - docker info
    - docker login -u $SPRYLAB_REGISTRY_USER -p $SPRYLAB_REGISTRY_PASSWORD $SPRYLAB_REGISTRY
  script:
    # Pull the cache image
    - docker pull ${TEST_CACHE_IMAGE_NAME} || true
    # Build our actual image
    - docker build
      --cache-from ${TEST_CACHE_IMAGE_NAME}
      -t ${TEST_IMAGE_NAME}
      -t ${TEST_CACHE_IMAGE_NAME}
      "."
    - docker push ${TEST_IMAGE_NAME}
    - docker push ${TEST_CACHE_IMAGE_NAME}

# Start a selenium headless setup, then run our test image from step one to test with it.
"Run E2E Tests":
  stage: test
  # FYI: this test runs inside a shell in the docker:stable image (which is configured to use the DIND setup we provide
  # FYI: via "services". Unfortunately we cannot directly use our "testing" image, as we do not have access to the
  # FYI: internal docker registry from the test runner
  image: docker:stable
  variables:
    TEST_IMAGE_NAME: ${SPRYLAB_REGISTRY}/${BASE_IMAGE_NAME}:${CI_COMMIT_SHORT_SHA}
  before_script:
    - docker info
    - docker login -u $SPRYLAB_REGISTRY_USER -p $SPRYLAB_REGISTRY_PASSWORD $SPRYLAB_REGISTRY
    # ToDo: It would be great to use an image that has docker AND docker-compose
    # ToDo: so we don't need to download it every time
    - apk add --no-cache docker-compose
    # Start the hub setup (just for this test)
    - docker-compose up -d
  script:
    - docker-compose ps
    # Find out the actual name of the "hub" container we need to connect to
    - export SELENIUM_HUB_CONTAINER_NAME=`docker-compose ps | grep hub | awk '{print $1}'`
    - echo $SELENIUM_HUB_CONTAINER_NAME
    # Start a container with a dummy command so we can 'exec' commands inside the running container
    # Note that the testing container and the docker-compose container share the same network, else, the container could
    # not communicate with each other!
    - docker run --name testrunner-${CI_COMMIT_SHORT_SHA} --network="selenium-headless-network-${CI_JOB_ID}" -e "SELENIUM_HUB_HOST=$SELENIUM_HUB_CONTAINER_NAME" -tid ${TEST_IMAGE_NAME} /bin/ash -c "sleep 9999"
    # Create a folder to store tests results = video captures in
    - docker exec testrunner-${CI_COMMIT_SHORT_SHA} mkdir -p _results_
    # Run the actual tests
    - docker exec testrunner-${CI_COMMIT_SHORT_SHA} npm run testRemoteChrome
  after_script:
    # Collect + transfer test results
    # Pack in an archive
    - docker exec testrunner-${CI_COMMIT_SHORT_SHA} tar -czvf test-recordings.tar.gz _results_
    # Transfer it via stdout and base64 to <this> container (the docker:stable container)
    - docker exec testrunner-${CI_COMMIT_SHORT_SHA} base64 test-recordings.tar.gz > test-recordings.tar.gz.base64
    - base64 -d test-recordings.tar.gz.base64 > test-recordings.tar.gz
    # Unpack it so gitlab can later collect the _results_ folder as job artifacts
    - tar -xzvf test-recordings.tar.gz
    # Teardown the testing container
    - docker rm -f testrunner-${CI_COMMIT_SHORT_SHA} || true
    # Stop the selenium setup
    - docker-compose down || true
  artifacts:
    when: always
    expire_in: 15 days
    paths:
      - _results_
